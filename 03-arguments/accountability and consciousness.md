Does [[accountability]] imply that the [[agent]] is conscious of its objectives?

In order for an agent to control it's interactions within a system, in order to reach its objectives, the agent needs to
* be self-aware in the sense that it knows how it can interact with the system and it knows its objective.
* have a model of the system in order to predict the system's feedback on its interactions.
  As the agent itself is part of the system model, this must include some level of self-reflection.

Is this already sufficient to call an agent conscious?
